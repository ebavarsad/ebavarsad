{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8ed790",
   "metadata": {},
   "source": [
    "# Titanic Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de248c85",
   "metadata": {},
   "source": [
    "This notebook will explain how I was able to predict the fate of 417 passengers that were on the Titanic by training various models based on 890 passengers of the same voyage.  \n",
    "\n",
    "The goal is to fill the survived column with as many correct values as possible.  First I am going to explain how I prepared the data.  Then I will try a few models that will keep my precision for predicting above 80%.  We will look at **<span style=\"color: red\">CatBoost</span>**, a tree-based ensemble, **<span style=\"color: blue\">Sequential</span>** from **<span style=\"color: black\">tensorflow</span>**, and **<span style=\"color: green\">Logistic Regression</span>** from **<span style=\"color: black\">sklearn.linear_model</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5611563",
   "metadata": {},
   "source": [
    "## 1. Check and Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7093d3",
   "metadata": {},
   "source": [
    "Let's set ourselves up for a quick washing of the titanic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5b95ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0dad89",
   "metadata": {},
   "source": [
    "Here is the function we will use to set up our data for modeling.  We set thresholds for how many titles and decks we want to allow for the hot encoding the models will do.  For titles we will use the top 10 distinct titles, and 1 \"other\" category.  Decks will therefore go with the top 20 categoties and 1 \"other\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0238e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(df, title_thresh=10, deck_thresh=20):\n",
    "    \n",
    "    # build a deck category from \"cabin\" by taking the first letter\n",
    "    df[\"Cabin\"] = df[\"Cabin\"].fillna(\"Unknown\")\n",
    "    df[\"Deck\"]  = df[\"Cabin\"].str[0]\n",
    "    \n",
    "    # consolidate the remainder decks\n",
    "    deck_counts   = df[\"Deck\"].value_counts()\n",
    "    common_decks  = deck_counts[ deck_counts >= deck_thresh ].index\n",
    "    df[\"Deck\"]    = df[\"Deck\"].where(df[\"Deck\"].isin(common_decks), \"Other\")\n",
    "\n",
    "    # build a title category from \"title\"\n",
    "    df[\"Title\"] = df[\"Name\"].str.extract(r',\\s*([^\\.]+)\\.', expand=False)\n",
    "\n",
    "    # consolidate remainder titles\n",
    "    title_counts  = df[\"Title\"].value_counts()\n",
    "    common_titles = title_counts[ title_counts >= title_thresh ].index\n",
    "    df[\"Title\"]   = df[\"Title\"].where(df[\"Title\"].isin(common_titles), \"Other\")\n",
    "\n",
    "    # replace missing age and fare with values from grouping and stats\n",
    "    age_meds = df.groupby([\"Pclass\",\"Title\"])[\"Age\"].median()\n",
    "    df[\"Age\"] = df.apply(\n",
    "        lambda r: age_meds.loc[(r.Pclass, r.Title)] if pd.isna(r.Age) else r.Age,\n",
    "        axis=1\n",
    "    )\n",
    "    fare_meds = df.groupby([\"Pclass\",\"Embarked\"])[\"Fare\"].median()\n",
    "    df[\"Fare\"] = df.apply(\n",
    "        lambda r: fare_meds.loc[(r.Pclass, r.Embarked)] if pd.isna(r.Fare) else r.Fare,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # i know its 3 or 4 lines, but we also need to fill in the missing embarked values :-D\n",
    "    emb_modes = df.groupby(\"Pclass\")[\"Embarked\"].agg(lambda x: x.mode().iloc[0])\n",
    "    df[\"Embarked\"] = df.apply(\n",
    "        lambda r: emb_modes.loc[r.Pclass] if pd.isna(r.Embarked) else r.Embarked,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # check to see who was lone wolfing the titantic adventure\n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "    df[\"IsAlone\"]    = (df[\"FamilySize\"] == 1).astype(int)\n",
    "\n",
    "    # create bins for age groups\n",
    "    df['AgeGroup'] = pd.cut(\n",
    "        df['Age'],\n",
    "        bins=[0, 12, 18, 35, 60, np.inf],\n",
    "        labels=['Child','Teen','Adult','MidAge','Senior']\n",
    "    )\n",
    "\n",
    "    # create quartiles for fare\n",
    "    df['FareBand'] = pd.qcut(\n",
    "        df['Fare'],\n",
    "        q=4,\n",
    "        labels=['Low','Med','High','VeryHigh']\n",
    "    )\n",
    "    \n",
    "    # get rid of useless columns\n",
    "    drop_cols = [\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"]\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d298331",
   "metadata": {},
   "source": [
    "Now we will start looking at the models, let's first start with a tree-based ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec1c5d",
   "metadata": {},
   "source": [
    "## 2. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16940fbd",
   "metadata": {},
   "source": [
    "**<span style=\"color: red\">CatBoost</span>** has a lot of benefits that give it an edge over other models.  It does its own hot encoding, internally learns efficient “combinatorial” features, which was key for filling in unknown values in the data, and it use ordered boosting to avoid overfitting.  It can be a bit too much for a small set like this one (under 1000 lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb95401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6428827\ttest: 0.6383958\tbest: 0.6383958 (0)\ttotal: 2.54ms\tremaining: 1.27s\n",
      "100:\tlearn: 0.2752394\ttest: 0.3241218\tbest: 0.3214858 (96)\ttotal: 280ms\tremaining: 1.1s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.3185820174\n",
      "bestIteration = 116\n",
      "\n",
      "Shrink model to first 117 iterations.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_clean = cleaner(train)\n",
    "test_clean = cleaner(test)\n",
    "\n",
    "# cat calls\n",
    "cat_cols = ['Pclass','Sex','Embarked','Title','Deck','AgeGroup','FareBand']\n",
    "\n",
    "for df in (train_clean, test_clean):\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].astype(object).fillna(\"Missing\").astype(str)\n",
    "\n",
    "# train, validate\n",
    "X = train_clean.drop(\"Survived\", axis=1)\n",
    "y = train_clean[\"Survived\"]\n",
    "\n",
    "# sklearns train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=15\n",
    ")\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_seed=15,\n",
    "    verbose=100\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_cols,\n",
    "    eval_set=(X_val, y_val),\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "preds = model.predict(test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097539bf",
   "metadata": {},
   "source": [
    "Here we check out how well **<span style=\"color: red\">CatBoost</span>** did with its predicting using **<span style=\"color: black\">sklearn.metrics</span>**.  We have a our little basic toolbox to measure the fitness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292d7a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.8771\n",
      "Validation ROC AUC  : 0.9255\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       110\n",
      "           1       0.86      0.81      0.84        69\n",
      "\n",
      "    accuracy                           0.88       179\n",
      "   macro avg       0.87      0.86      0.87       179\n",
      "weighted avg       0.88      0.88      0.88       179\n",
      "\n",
      "Confusion Matrix:\n",
      "[[101   9]\n",
      " [ 13  56]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "y_pred      = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "print(f\"Validation Accuracy : {accuracy_score(y_val, y_pred):.4f}\")\n",
    "print(f\"Validation ROC AUC  : {roc_auc_score  (y_val, y_pred_prob):.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1018d",
   "metadata": {},
   "source": [
    "This is a very solid base model with high overall accuracy and AUC.  It stuggles a tad more with the survivor side (higher false-negative rate for class 1).  For survivors there is a 86 % precision and 81 % recall, so about 19 % of actual survivors are being missed (false negatives).  \n",
    "\n",
    "87.7% accuracy is a good prediction rate, but what stands out is what the ROC AUC at near 93%, showing that the model does a good job of distinguishing who is a survivor and who isn't"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1225632",
   "metadata": {},
   "source": [
    "## 3. Using Tensorflow's \"Sequential\" Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027fdff1",
   "metadata": {},
   "source": [
    "In this section we will use **<span style=\"color: blue\">Sequential</span>** from **<span style=\"color: black\">tensorflow.keras</span>** to build a neural network.  **<span style=\"color: blue\">Sequential</span>** is one of the simplest ways to build a neural network in **<span style=\"color: black\">tensorflow's</span>** high-level **<span style=\"color: black\">keras</span>** API. It represents a linear stack of layers, where you feed the output of one layer directly into the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac4c8f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eb64/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/eb64/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 48ms/step - accuracy: 0.6362 - loss: 0.6339 - val_accuracy: 0.6536 - val_loss: 0.5790\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.7135 - loss: 0.5714 - val_accuracy: 0.7263 - val_loss: 0.5178\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.7556 - loss: 0.4979 - val_accuracy: 0.7877 - val_loss: 0.4829\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.7949 - loss: 0.4776 - val_accuracy: 0.7877 - val_loss: 0.4558\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - accuracy: 0.8076 - loss: 0.4321 - val_accuracy: 0.8045 - val_loss: 0.4406\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8062 - loss: 0.4442 - val_accuracy: 0.8212 - val_loss: 0.4328\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8146 - loss: 0.4334 - val_accuracy: 0.8268 - val_loss: 0.4258\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8160 - loss: 0.4306 - val_accuracy: 0.8268 - val_loss: 0.4231\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8076 - loss: 0.4332 - val_accuracy: 0.8547 - val_loss: 0.4233\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8455 - loss: 0.4042 - val_accuracy: 0.8492 - val_loss: 0.4208\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8315 - loss: 0.4151 - val_accuracy: 0.8659 - val_loss: 0.4178\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8301 - loss: 0.4006 - val_accuracy: 0.8547 - val_loss: 0.4165\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8371 - loss: 0.3886 - val_accuracy: 0.8324 - val_loss: 0.4171\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8385 - loss: 0.3960 - val_accuracy: 0.8492 - val_loss: 0.4162\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8399 - loss: 0.3957 - val_accuracy: 0.8324 - val_loss: 0.4165\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8371 - loss: 0.3860 - val_accuracy: 0.8436 - val_loss: 0.4186\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8329 - loss: 0.3791 - val_accuracy: 0.8380 - val_loss: 0.4202\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8385 - loss: 0.3781 - val_accuracy: 0.8380 - val_loss: 0.4182\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8413 - loss: 0.3829 - val_accuracy: 0.8324 - val_loss: 0.4178\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8441 - loss: 0.3803 - val_accuracy: 0.8380 - val_loss: 0.4183\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8427 - loss: 0.3821 - val_accuracy: 0.8156 - val_loss: 0.4180\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8539 - loss: 0.3610 - val_accuracy: 0.8324 - val_loss: 0.4154\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8511 - loss: 0.3747 - val_accuracy: 0.8380 - val_loss: 0.4165\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8539 - loss: 0.3637 - val_accuracy: 0.8212 - val_loss: 0.4192\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8511 - loss: 0.3636 - val_accuracy: 0.8101 - val_loss: 0.4217\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8427 - loss: 0.3741 - val_accuracy: 0.8324 - val_loss: 0.4212\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8581 - loss: 0.3511 - val_accuracy: 0.8324 - val_loss: 0.4196\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8610 - loss: 0.3480 - val_accuracy: 0.8324 - val_loss: 0.4243\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8427 - loss: 0.3575 - val_accuracy: 0.8324 - val_loss: 0.4224\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8553 - loss: 0.3552 - val_accuracy: 0.8101 - val_loss: 0.4272\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8624 - loss: 0.3410 - val_accuracy: 0.8212 - val_loss: 0.4270\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8624 - loss: 0.3271 - val_accuracy: 0.8324 - val_loss: 0.4285\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8624 - loss: 0.3469 - val_accuracy: 0.8212 - val_loss: 0.4292\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8539 - loss: 0.3662 - val_accuracy: 0.8212 - val_loss: 0.4273\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8736 - loss: 0.3333 - val_accuracy: 0.8380 - val_loss: 0.4286\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8610 - loss: 0.3399 - val_accuracy: 0.8156 - val_loss: 0.4323\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8750 - loss: 0.3228 - val_accuracy: 0.8156 - val_loss: 0.4341\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8610 - loss: 0.3634 - val_accuracy: 0.8156 - val_loss: 0.4367\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8694 - loss: 0.3316 - val_accuracy: 0.8156 - val_loss: 0.4369\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8666 - loss: 0.3518 - val_accuracy: 0.8156 - val_loss: 0.4381\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8680 - loss: 0.3282 - val_accuracy: 0.8101 - val_loss: 0.4412\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8638 - loss: 0.3347 - val_accuracy: 0.8101 - val_loss: 0.4407\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8750 - loss: 0.3237 - val_accuracy: 0.8268 - val_loss: 0.4406\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8666 - loss: 0.3397 - val_accuracy: 0.8156 - val_loss: 0.4393\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8736 - loss: 0.3247 - val_accuracy: 0.8156 - val_loss: 0.4418\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8722 - loss: 0.3279 - val_accuracy: 0.8156 - val_loss: 0.4428\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8722 - loss: 0.3348 - val_accuracy: 0.8101 - val_loss: 0.4437\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8792 - loss: 0.3356 - val_accuracy: 0.8212 - val_loss: 0.4424\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - accuracy: 0.8792 - loss: 0.3146 - val_accuracy: 0.8156 - val_loss: 0.4424\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 3ms/step - accuracy: 0.8736 - loss: 0.3146 - val_accuracy: 0.8101 - val_loss: 0.4486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# We like to recycle here\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_clean = cleaner(train)\n",
    "test_clean = cleaner(test)\n",
    "\n",
    "# you would think i got rid of all the nans....\n",
    "cat_cols = ['Pclass','Sex','Embarked','Title','Deck','AgeGroup','FareBand']\n",
    "for df in (train_clean, test_clean):\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].astype(object)\n",
    "        df[c] = df[c].fillna('Missing').astype(str)\n",
    "\n",
    "# the training begins now\n",
    "X = train_clean.drop(\"Survived\", axis=1)\n",
    "y = train_clean[\"Survived\"].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# we have to define what is numerical and what is categorial for Sequential\n",
    "num_cols = [\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"FamilySize\",\"IsAlone\"]\n",
    "\n",
    "# build piplines\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  StandardScaler())\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\",  OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "# prepare the fitting\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc   = preprocessor.transform(X_val)\n",
    "\n",
    "# build our Sequential MultiLayer Preceptron and compile it\n",
    "model = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(X_train_proc.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64,  activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(1,   activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# train the validation model\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train,\n",
    "    validation_data=(X_val_proc, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e4a3b",
   "metadata": {},
   "source": [
    "And the validation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17a84ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss: 0.4486\n",
      "Validation accuracy: 0.8101\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "ROC AUC: 0.8498\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       110\n",
      "           1       0.80      0.68      0.73        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.79      0.79       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "Confusion Matrix:\n",
      "[[98 12]\n",
      " [22 47]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_loss, val_acc = model.evaluate(X_val_proc, y_val, verbose=0)\n",
    "print(f\"\\nValidation loss: {val_loss:.4f}\")\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "y_val_prob = model.predict(X_val_proc).ravel()\n",
    "y_val_pred = (y_val_prob >= 0.5).astype(int)\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, y_val_prob):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622e445",
   "metadata": {},
   "source": [
    "The results for this model fall behind that of the **<span style=\"color: red\">CatBoost</span>**, with an 81% precision rate and 85% for the ROC-AUC.  The confusion matrix shows that the model is classifying most non-survivors (89 % recall) but missing nearly one-third of survivors (68 % recall), leading to 22 false negatives.  MLP's normally do very well with nonlinear regressions, but because of the size of the Titanic data, it can't quite wrap its net around the numbers.  MLP's need a certain amount of depth and training data to get the most out of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39247e",
   "metadata": {},
   "source": [
    "## 3. SKLearn's Linear-Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cc519",
   "metadata": {},
   "source": [
    "**<span style=\"color: green\">LogisticRegression's</span>** coefficients can tell you exactly how each standardized feature affects the log-odds of survival, which is invaluable for understanding passenger risk factors and makes it a good choice to use on the Titanic data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8204a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eb64/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Age&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;,\n",
       "                                                   &#x27;Fare&#x27;, &#x27;FamilySize&#x27;,\n",
       "                                                   &#x27;IsAlone&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  [&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Embarked&#x27;,\n",
       "                                                   &#x27;Title&#x27;, &#x27;Deck&#x27;, &#x27;AgeGroup&#x27;,\n",
       "                                                   &#x27;FareBand&#x27;])])),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Age&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;,\n",
       "                                                   &#x27;Fare&#x27;, &#x27;FamilySize&#x27;,\n",
       "                                                   &#x27;IsAlone&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  [&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Embarked&#x27;,\n",
       "                                                   &#x27;Title&#x27;, &#x27;Deck&#x27;, &#x27;AgeGroup&#x27;,\n",
       "                                                   &#x27;FareBand&#x27;])])),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">prep: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scale&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;Age&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Fare&#x27;, &#x27;FamilySize&#x27;,\n",
       "                                  &#x27;IsAlone&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 [&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Embarked&#x27;, &#x27;Title&#x27;, &#x27;Deck&#x27;,\n",
       "                                  &#x27;AgeGroup&#x27;, &#x27;FareBand&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Fare&#x27;, &#x27;FamilySize&#x27;, &#x27;IsAlone&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Embarked&#x27;, &#x27;Title&#x27;, &#x27;Deck&#x27;, &#x27;AgeGroup&#x27;, &#x27;FareBand&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scale',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Age', 'SibSp', 'Parch',\n",
       "                                                   'Fare', 'FamilySize',\n",
       "                                                   'IsAlone']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  ['Pclass', 'Sex', 'Embarked',\n",
       "                                                   'Title', 'Deck', 'AgeGroup',\n",
       "                                                   'FareBand'])])),\n",
       "                ('clf', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# one more time\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_clean = cleaner(train)\n",
    "test_clean = cleaner(test)\n",
    "\n",
    "# just in case\n",
    "cat_cols = ['Pclass','Sex','Embarked','Title','Deck','AgeGroup','FareBand']\n",
    "for df in (train_clean, test_clean):\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].astype(object)\n",
    "        df[c] = df[c].fillna('Missing').astype(str)\n",
    "\n",
    "# train test split\n",
    "X = train_clean.drop(\"Survived\", axis=1)\n",
    "y = train_clean[\"Survived\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=15\n",
    "    )\n",
    "\n",
    "# behold, our pipelines\n",
    "num_cols = [\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"FamilySize\",\"IsAlone\"]\n",
    "num_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale',  StandardScaler())\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_cols),\n",
    "    ('cat', cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "# our logistic regression pipeline\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('clf',  LogisticRegression(solver='lbfgs', max_iter=1000))\n",
    "])\n",
    "\n",
    "# now we train\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6161eb24",
   "metadata": {},
   "source": [
    "Now let's check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1262e26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8659217877094972\n",
      "ROC AUC:           0.9127799736495388\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       110\n",
      "           1       0.82      0.84      0.83        69\n",
      "\n",
      "    accuracy                           0.87       179\n",
      "   macro avg       0.86      0.86      0.86       179\n",
      "weighted avg       0.87      0.87      0.87       179\n",
      "\n",
      "Confusion Matrix:\n",
      " [[97 13]\n",
      " [11 58]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_val)\n",
    "y_prob = pipe.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"ROC AUC:          \", roc_auc_score(y_val, y_prob))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d53c28",
   "metadata": {},
   "source": [
    "The results from **<span style=\"color: green\">LogisticRegression's</span>** are compareable with those of **<span style=\"color: red\">CatBoost</span>**.  Precision/Recall for non-survivors are 0.90/0.88, and for survivors are 0.82/0.84.  It slightly under‐predicts survivors but does so more evenly than the MLP did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af0ab28",
   "metadata": {},
   "source": [
    "Future Projects\n",
    "\n",
    "- Pairing models to push for accuracy past 95%\n",
    "- Experiment with other treebase ensembles "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
