{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84dd4971",
   "metadata": {},
   "source": [
    "# Using K-Nearest Neighbors to Classify Iris Flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66214dd6",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299053a",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate the power and simplicity of the **k-nearest neighbors (k-NN)** algorithm by applying it to the classic **Iris flower dataset**. This dataset contains measurements of iris flowers' sepals and petals across three species (*setosa*, *versicolor*, and *virginica*), making it an ideal choice for supervised classification.\n",
    "\n",
    "Our goals are to:\n",
    "- Load and explore the dataset to understand its features and target classes.\n",
    "- Prepare the data by handling categorical labels and scaling features, which is crucial for distance-based algorithms like k-NN.\n",
    "- Implement the **k-NN classifier** from scratch using `scikit-learn`, tuning the `k` parameter to observe its impact on model performance.\n",
    "- Evaluate our model using metrics such as accuracy, confusion matrices, and classification reports to ensure robust performance.\n",
    "\n",
    "By the end of this analysis, we will not only have a working k-NN model that can accurately predict iris species, but also a deeper understanding of how proximity-based classification works and how critical preprocessing is in achieving meaningful results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe60ee",
   "metadata": {},
   "source": [
    "## 2. Data Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8153f48",
   "metadata": {},
   "source": [
    "We are going to load in the data and take a look at it before running it through the K-NN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07e435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris_df = pd.read_csv('iris.csv')\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e763d",
   "metadata": {},
   "source": [
    "Weâ€™ve successfully loaded the Iris dataset into a pandas DataFrame and displayed the first few rows to get a quick look at the data structure. This CSV file, sourced from Kaggle, contains the same classic measurements as the built-in `sklearn.datasets.load_iris()` version, but working directly with the CSV allows us to showcase practical data handling steps like file reading, exploratory analysis, and label encoding.\n",
    "\n",
    "Let's take a deeper look into the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969edbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             150 non-null    int64  \n",
      " 1   SepalLengthCm  150 non-null    float64\n",
      " 2   SepalWidthCm   150 non-null    float64\n",
      " 3   PetalLengthCm  150 non-null    float64\n",
      " 4   PetalWidthCm   150 non-null    float64\n",
      " 5   Species        150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# this is a function that spits out data on the dataset, like NaN counts and stuff\n",
    "\n",
    "def check_data(df):\n",
    "    \n",
    "    df.info()\n",
    "    df.describe()\n",
    "    df.isnull().sum()\n",
    "    df['Species'].value_counts()\n",
    "    \n",
    "check_data(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f15312",
   "metadata": {},
   "source": [
    "From our initial data check, we see that:\n",
    "\n",
    "- There are no missing values (yay!, NaNs make me cringe)\n",
    "\n",
    "- The four main features (`SepalLengthCm`, `SepalWidthCm`, `PetalLengthCm`, `PetalWidthCm`) are all numeric (`float64`), as expected for measurements in centimeters.  We are going to rename these columns to shorten them for legibility\n",
    "\n",
    "- The species column is an object type with three types of Iris flowers names as values.  We will deal with this next\n",
    "\n",
    "- The `Id` column is just an index and we won't need it, unless I find out some try hard on kaggle used it to increase their precision by 1% with it.\n",
    "\n",
    "Overall, the data is **clean, complete, and well-structured**, which makes it an ideal candidate to demonstrate the k-NN algorithm without additional cleaning complications.  Neat!\n",
    "\n",
    "Now let's clean up the column names, encode the \"Species\" column, and I guess we can drop the \"Id\" column as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfeb344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found by LabelEncoder: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "Label encoding mapping: {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal_Length  Sepal_Width  Petal_Length  Petal_Width  Species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def data_prepper(df):\n",
    "    \n",
    "    df = df.rename(columns={\"SepalLengthCm\":\"Sepal_Length\", \"SepalWidthCm\":\"Sepal_Width\",\n",
    "                       \"PetalLengthCm\":\"Petal_Length\", \"PetalWidthCm\":\"Petal_Width\"})\n",
    "    \n",
    "    df = df.drop(columns=['Id'], axis=1)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # fit on the three values in species and print the labels\n",
    "    le.fit(df['Species'])\n",
    "    print(\"Classes found by LabelEncoder:\", le.classes_)\n",
    "    \n",
    "    # see the mapping\n",
    "    mapping = {label: idx for idx, label in enumerate(le.classes_)}\n",
    "    print(\"Label encoding mapping:\", mapping)\n",
    "    \n",
    "    df['Species'] = le.fit_transform(df['Species'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "iris_clean = data_prepper(iris_df)\n",
    "    \n",
    "iris_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bfcc44",
   "metadata": {},
   "source": [
    "Now let's go to the next part, where we begin to train the data for a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88781fa9",
   "metadata": {},
   "source": [
    "##  3. Training and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef6bda",
   "metadata": {},
   "source": [
    "Now that our dataset is cleaned and the target labels are properly encoded, we're ready to build the full machine learning pipeline. This step includes:\n",
    "\n",
    "- **Separating features and target:** Extracting the measurement columns as input features (`X`) and the encoded species as the target variable (`y`)\n",
    "\n",
    "- **Splitting into training and test sets:** Ensuring we have data to evaluate how well the model generalizes to unseen examples.\n",
    "\n",
    "- **Scaling the features:** Since k-NN relies on distance calculations, it's critical to standardize our data so that all features contribute equally, regardless of their original units.\n",
    "\n",
    "- **Fitting the k-NN model:** We'll train a k-nearest neighbors classifier with a chosen `k` value, ready to predict new iris samples.\n",
    "\n",
    "With our k-NN model trained and validated, we can now assess its real-world performance by making predictions on the test set. We'll generate metrics such as accuracy, the macro-averaged F1-score (which gives equal weight to each class regardless of support), and a detailed classification report to understand how well our model distinguishes between the three iris species.\n",
    "\n",
    "By printing the confusion matrix alongside these scores, we gain a deeper look into which classes are most frequently misclassified. This analysis is crucial for diagnosing the strengths and limitations of our chosen `k` value, and will also serve as the foundation for any hyperparameter tuning we perform to further optimize the model.\n",
    "\n",
    "We'll wrap this entire process into a reusable function to streamline experimentation and then do a detailed analysis of the results and consider optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda66063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with k=5\n",
      "Accuracy on test set: 0.90\n",
      "Macro F1-score: 0.90\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3  7]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.77      1.00      0.87        10\n",
      "           2       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.92      0.90      0.90        30\n",
      "weighted avg       0.92      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "def train_knn_model(df, k):\n",
    "    \n",
    "    # separate features and target\n",
    "    X = df.drop(columns=['Species'])\n",
    "    y = df['Species']\n",
    "    \n",
    "    # split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size = 0.2, random_state = 15, stratify = y\n",
    "    )\n",
    "    \n",
    "    # scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # fit k-NN model\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"Model trained with k={k}\")\n",
    "    print(f\"Accuracy on test set: {acc:.2f}\")\n",
    "    print(f\"Macro F1-score: {f1:.2f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return f1\n",
    "    \n",
    "f1_score = train_knn_model(iris_clean, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a720f1c",
   "metadata": {},
   "source": [
    "Our initial k-NN model, trained on the standardized Iris dataset with a chosen `k` value, produced strong classification metrics. The confusion matrix and classification report confirm that the model effectively distinguishes between the three iris species, with high precision, recall, and macro-averaged F1-scores across classes. These results highlight the strength of even a straightforward distance-based approach like k-NN when paired with appropriate preprocessing and scaling.\n",
    "\n",
    "However, the value of `k` plays a crucial role in how well k-NN generalizes. A poorly chosen `k` could lead to overfitting or underfitting, directly impacting predictive performance. To ensure we have the most robust classifier possible, weâ€™ll next explore optimizing `k` using the macro F1-score as our objective metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af6e530",
   "metadata": {},
   "source": [
    "## 4. Optimization  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea60688",
   "metadata": {},
   "source": [
    "In this section, we'll systematically vary `k` across a reasonable range of values, training a separate k-NN model for each. By recording the resulting macro F1-scores, we can identify the value of `k` that achieves the best balance between precision and recall across all classes.\n",
    "\n",
    "Finally, we'll visualize this relationship by plotting F1-score versus `k`, allowing us to clearly see how model performance changes as we adjust the number of neighbors. This will guide us to select the optimal `k` for our final, tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7881ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
